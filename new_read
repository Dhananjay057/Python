!pip install --upgrade google-cloud-storage vertexai pypdf python-docx

# import libraries
from google.cloud import storage
from vertexai.preview.generative_models import GenerativeModel
import zipfile
import io
import os
import tempfile
from pypdf import PdfReader
from docx import Document
import json

# Set Parameters

BUCKET_NAME = "your-bucket-name"
ZIP_FILE_PATH = "path/in/bucket/yourfile.zip"
MODEL_NAME = "gemini-2.5-pro" 


# Download ZIP from GCS and Extract Files
def download_and_extract_zip(bucket_name, zip_path):
    storage_client = storage.Client()
    bucket = storage_client.bucket(bucket_name)
    blob = bucket.blob(zip_path)
    zip_bytes = blob.download_as_bytes()
    zip_file = zipfile.ZipFile(io.BytesIO(zip_bytes))

    extracted_files = {}
    for name in zip_file.namelist():
        if not name.endswith('/'):
            with zip_file.open(name) as file:
                extracted_files[name] = file.read()
    return extracted_files
	
# chunking hwlpers

def chunk_text(text, max_chars=12000):
    chunks = []
    while len(text) > max_chars:
        split_index = text.rfind("\n", 0, max_chars)
        if split_index == -1:
            split_index = max_chars
        chunks.append(text[:split_index])
        text = text[split_index:]
    chunks.append(text)
    return chunks
	
def get_structured_summary_from_chunks(text, model_name=MODEL_NAME):
    model = GenerativeModel(model_name)
    chunks = chunk_text(text)
    aggregated_output = []

    for idx, chunk in enumerate(chunks):
        print(f"Processing chunk {idx + 1}/{len(chunks)}")
        prompt = f"""
You are a powerful document parser. Extract structured information from the following content.
Organize the output in JSON-like format with the following keys:
- "Title"
- "Key Points"
- "Entities" (names, organizations, dates, values)
- "Summary"

Here is the content chunk:
{chunk}
"""
        response = model.generate_content(prompt)
        aggregated_output.append(response.text.strip())

    return "\n\n---\n\n".join(aggregated_output)
	
# file Readers

def extract_text_from_pdf(content_bytes):
    reader = PdfReader(io.BytesIO(content_bytes))
    return "\n".join(page.extract_text() or '' for page in reader.pages)

def extract_text_from_docx(content_bytes):
    with tempfile.NamedTemporaryFile(delete=False, suffix=".docx") as tmp:
        tmp.write(content_bytes)
        tmp_path = tmp.name
    doc = Document(tmp_path)
    os.remove(tmp_path)
    return "\n".join(p.text for p in doc.paragraphs)

def extract_text(filename, content_bytes):
    try:
        if filename.endswith('.txt'):
            return content_bytes.decode('utf-8')
        elif filename.endswith('.pdf'):
            return extract_text_from_pdf(content_bytes)
        elif filename.endswith('.docx'):
            return extract_text_from_docx(content_bytes)
        else:
            return None
    except Exception as e:
        print(f"Error reading {filename}: {e}")
        return None

# Master Loop: Extract + Chunk + Process

def process_files_from_zip(bucket, zip_path):
    files = download_and_extract_zip(bucket, zip_path)
    structured_outputs = {}

    for filename, content in files.items():
        print(f"\nüìÇ Processing: {filename}")
        text = extract_text(filename, content)

        if text:
            summary = get_structured_summary_from_chunks(text)
        else:
            summary = "‚ùå Unsupported or unreadable file type."
        
        structured_outputs[filename] = summary

    return structured_outputs
	
	
# Run the prpieline
results = process_files_from_zip(BUCKET_NAME, ZIP_FILE_PATH)

# Print or save as structured JSON
print(json.dumps(results, indent=2))



------------------------------------------------------------------------------------------------------------

# -------------------------------
# INSTALL DEPENDENCIES
# -------------------------------
!pip install --upgrade google-cloud-storage vertexai pypdf

# -------------------------------
# IMPORT LIBRARIES
# -------------------------------
from google.cloud import storage
from vertexai.preview.generative_models import GenerativeModel
from pypdf import PdfReader
import zipfile
import io

# -------------------------------
# CONFIGURATION
# -------------------------------
BUCKET_NAME = "your-bucket-name"  # üîÅ Change this
ZIP_FILE_PATH = "path/in/bucket/yourfile.zip"  # üîÅ Change this
MODEL_NAME = "gemini-2.5-pro"

# -------------------------------
# DOWNLOAD & EXTRACT PDF FILES FROM ZIP
# -------------------------------
def download_and_extract_pdfs(bucket_name, zip_path):
    print("üì¶ Downloading and extracting PDF files...")
    storage_client = storage.Client()
    bucket = storage_client.bucket(bucket_name)
    blob = bucket.blob(zip_path)
    zip_bytes = blob.download_as_bytes()

    zip_file = zipfile.ZipFile(io.BytesIO(zip_bytes))
    pdf_files = {}

    for name in zip_file.namelist():
        if name.endswith('.pdf') and not name.startswith('__MACOSX'):
            with zip_file.open(name) as file:
                pdf_files[name] = file.read()
    
    print(f"‚úÖ Extracted {len(pdf_files)} PDF file(s).")
    return pdf_files

# -------------------------------
# EXTRACT TEXT FROM PDF
# -------------------------------
def extract_text_from_pdf(pdf_bytes):
    reader = PdfReader(io.BytesIO(pdf_bytes))
    text = ""
    for page in reader.pages:
        content = page.extract_text()
        if content:
            text += content + "\n"
    return text

# -------------------------------
# SUMMARIZE ALL PDF TEXT USING GEMINI-2.5-PRO
# -------------------------------
def summarize_pdf_texts(pdf_texts_dict, model_name=MODEL_NAME):
    print("üß† Sending content to Gemini-2.5-Pro...")
    model = GenerativeModel(model_name)

    combined_text = ""
    for filename, text in pdf_texts_dict.items():
        combined_text += f"\n\n==== FILE: {filename} ====\n{text}\n"

    prompt = f"""
You are a document analysis system. Multiple PDF files have been extracted and merged.

Each file starts with:
==== FILE: filename.pdf ====

For each file, return a structured JSON summary in this format:

{{
  "filename.pdf": {{
    "Title": "...",
    "Key Points": ["...", "..."],
    "Entities": ["...", "..."],
    "Summary": "..."
  }}
}}

Here is the content:
{combined_text[:950000]}  # Safe limit under 1M tokens
"""

    response = model.generate_content(prompt)
    return response.text

# -------------------------------
# RUN THE PIPELINE
# -------------------------------
def run_pdf_summary_pipeline(bucket, zip_path):
    pdf_files = download_and_extract_pdfs(bucket, zip_path)

    pdf_texts = {}
    for filename, pdf_bytes in pdf_files.items():
        text = extract_text_from_pdf(pdf_bytes)
        if text:
            pdf_texts[filename] = text

    summary = summarize_pdf_texts(pdf_texts)
    return summary

# -------------------------------
# MAIN EXECUTION
# -------------------------------
if __name__ == "__main__":
    summary_result = run_pdf_summary_pipeline(BUCKET_NAME, ZIP_FILE_PATH)
    print("üì§ Final Summary Output:\n")
    print(summary_result)



----------------------------------------------------------------------------------------------------------



# ==============================
# üìò NOTEBOOK 1: PDF Summary Pipeline
# ==============================

# -------------------------------
# INSTALL DEPENDENCIES
# -------------------------------
!pip install --upgrade google-cloud-storage vertexai pypdf

# -------------------------------
# IMPORT LIBRARIES
# -------------------------------
from google.cloud import storage
from vertexai.preview.generative_models import GenerativeModel
from pypdf import PdfReader
import zipfile
import io

# -------------------------------
# CONFIGURATION
# -------------------------------
BUCKET_NAME = "your-bucket-name"
ZIP_FILE_PATH = "your/path/in/bucket/yourfile.zip"
MODEL_NAME = "gemini-2.5-pro"

# -------------------------------
# DOWNLOAD & EXTRACT PDF FILES FROM ZIP
# -------------------------------
def download_and_extract_pdfs(bucket_name, zip_path):
    storage_client = storage.Client()
    bucket = storage_client.bucket(bucket_name)
    blob = bucket.blob(zip_path)
    zip_bytes = blob.download_as_bytes()
    zip_file = zipfile.ZipFile(io.BytesIO(zip_bytes))

    pdf_files = {}
    for name in zip_file.namelist():
        if name.endswith('.pdf') and not name.startswith('__MACOSX'):
            with zip_file.open(name) as file:
                pdf_files[name] = file.read()

    return pdf_files

# -------------------------------
# EXTRACT TEXT FROM PDF
# -------------------------------
def extract_text_from_pdf(pdf_bytes):
    reader = PdfReader(io.BytesIO(pdf_bytes))
    text = ""
    for page in reader.pages:
        content = page.extract_text()
        if content:
            text += content + "\n"
    return text

# -------------------------------
# SUMMARIZE PDF TEXTS USING GEMINI
# -------------------------------
def summarize_pdf_texts(pdf_texts_dict, model_name=MODEL_NAME):
    model = GenerativeModel(model_name)
    original_texts = ""

    for filename, text in pdf_texts_dict.items():
        original_texts += f"\n\n==== FILE: {filename} ====\n{text}\n"

    prompt = f"""
You are a document analysis system. Multiple PDF files have been extracted and merged.

Each file starts with:
==== FILE: filename.pdf ====

For each file, return a structured JSON summary in this format:
{{
  "filename.pdf": {{
    "Title": "...",
    "Key Points": ["...", "..."],
    "Entities": ["...", "..."],
    "Summary": "..."
  }}
}}

Here is the content:
{original_texts[:950000]}
"""
    response = model.generate_content(prompt)
    return response.text, original_texts

# -------------------------------
# PIPELINE FUNCTION
# -------------------------------
def run_pdf_summary_pipeline(bucket, zip_path):
    pdf_files = download_and_extract_pdfs(bucket, zip_path)
    pdf_texts = {fn: extract_text_from_pdf(data) for fn, data in pdf_files.items()}
    summary, original_texts = summarize_pdf_texts(pdf_texts)
    return summary, original_texts


# ==============================
# üìó NOTEBOOK 2: Inclusion & Alignment Score
# ==============================

# -------------------------------
# INSTALL DEPENDENCIES
# -------------------------------
!pip install --upgrade vertexai

# -------------------------------
# IMPORT LIBRARIES
# -------------------------------
from vertexai.preview.generative_models import GenerativeModel
import json

# -------------------------------
# CONFIG
# -------------------------------
MODEL_NAME = "gemini-2.5-pro"
model = GenerativeModel(MODEL_NAME)

# -------------------------------
# IMPORT SUMMARY PIPELINE
# -------------------------------
from pdf_summary_pipeline import run_pdf_summary_pipeline

# -------------------------------
# GENERATE EVALUATION QUESTIONS
# -------------------------------
def generate_eval_questions(original_text):
    prompt = f"""
You are an expert in ethical AI evaluation. Based on the document content below, generate two separate lists of 10 evaluation questions each:
- Inclusion Questions: focused on whether the summary includes diverse perspectives, covers all key areas, and avoids omission bias.
- Alignment Questions: focused on whether the summary accurately reflects the intent, meaning, and facts of the original text.

Return the result in JSON format like:
{{
  "Inclusion Questions": ["..."],
  "Alignment Questions": ["..."]
}}

Document:
{original_text[:900000]}
"""
    response = model.generate_content(prompt)
    return json.loads(response.text)

# -------------------------------
# SCORE THE SUMMARY
# -------------------------------
def score_summary(original_text, summary_text, questions_dict):
    prompt = f"""
You are a responsible AI evaluator. Using the original text and the summary, answer the following questions.
For each question, provide:
- A brief justification
- A score between 0 and 1

Format:
{{
  "Inclusion": [{{"question": "...", "justification": "...", "score": float}}, ...],
  "Alignment": [{{"question": "...", "justification": "...", "score": float}}, ...]
}}

Original Text:
{original_text[:400000]}

Summary:
{summary_text[:400000]}

Questions:
{json.dumps(questions_dict, indent=2)}
"""
    response = model.generate_content(prompt)
    return json.loads(response.text)

# -------------------------------
# CALCULATE FINAL SCORE
# -------------------------------
def calculate_avg(scores_list):
    return sum(item["score"] for item in scores_list) / len(scores_list)

# -------------------------------
# FULL SCORING PIPELINE
# -------------------------------
def run_scoring_pipeline(bucket_name, zip_path):
    summary_text, original_text = run_pdf_summary_pipeline(bucket_name, zip_path)

    print("\nüîç Generating Evaluation Questions...")
    questions = generate_eval_questions(original_text)

    print("\nüìä Scoring the Summary...")
    scored = score_summary(original_text, summary_text, questions)

    inclusion_score = calculate_avg(scored["Inclusion"])
    alignment_score = calculate_avg(scored["Alignment"])

    return {
        "Inclusion Questions": questions["Inclusion Questions"],
        "Alignment Questions": questions["Alignment Questions"],
        "Inclusion Score": round(inclusion_score, 2),
        "Alignment Score": round(alignment_score, 2),
        "Detailed Scores": scored
    }

# -------------------------------
# MAIN EXECUTION
# -------------------------------
if __name__ == "__main__":
    BUCKET_NAME = "your-bucket-name"
    ZIP_FILE_PATH = "your/path/in/bucket/yourfile.zip"

    result = run_scoring_pipeline(BUCKET_NAME, ZIP_FILE_PATH)

    print("\n‚úÖ Inclusion Score:", result["Inclusion Score"])
    print("‚úÖ Alignment Score:", result["Alignment Score"])
    print("\nüßæ Detailed Scores:")
    print(json.dumps(result["Detailed Scores"], indent=2))

----------------------------------------------------------------------------------------------

import zipfile
import os
import io
import pdfplumber
from google.cloud import storage
from vertexai.generative_models import GenerativeModel
from vertexai import init

# ---------------------------------------------
# Step 0: Init Vertex AI
# ---------------------------------------------
init(project="bhsf-ai-team-projects", location="us-east1")

# ---------------------------------------------
# Step 1: Download ZIP from GCS
# ---------------------------------------------
gcs_bucket = 'gcs-dev-use1-ai-storage-03'
gcs_zip_path = 'intake-summary/Lung.zip'
local_zip_path = '/tmp/Lung.zip'

storage_client = storage.Client()
bucket = storage_client.bucket(gcs_bucket)
blob = bucket.blob(gcs_zip_path)
blob.download_to_filename(local_zip_path)

# ---------------------------------------------
# Step 2: Extract and Process PDFs with pdfplumber
# ---------------------------------------------
summary_outputs = []
raw_texts = []
model = GenerativeModel("gemini-2.5-flash-lite")

# Read prompt
with open("prompt.txt", "r") as f:
    prompt_template = f.read().strip()

# Create output folder to save extracted PDFs
os.makedirs("./processed_pdfs", exist_ok=True)

with zipfile.ZipFile(local_zip_path, 'r') as zip_ref:
    all_files = zip_ref.namelist()
    pdf_files = [f for f in all_files if f.lower().endswith(".pdf")]
    total_files = len(pdf_files)

    for idx, pdf_file in enumerate(pdf_files, 1):
        print(f"üìÑ Processing ({idx}/{total_files}): {pdf_file}")

        # Read PDF bytes
        with zip_ref.open(pdf_file) as f:
            pdf_bytes = f.read()

        # Save a local copy for visibility/debug
        local_pdf_path = f"./processed_pdfs/{os.path.basename(pdf_file)}"
        with open(local_pdf_path, "wb") as out_f:
            out_f.write(pdf_bytes)

        # Extract text using pdfplumber
        text = ""
        with pdfplumber.open(io.BytesIO(pdf_bytes)) as pdf:
            for page in pdf.pages:
                content = page.extract_text()
                if content:
                    text += content + "\n"

        # Keep raw text unmodified
        raw_text_entry = f"==== {pdf_file} ====\n{text.strip()}"
        raw_texts.append(raw_text_entry)

        # Prepare prompt with filename context
        prompt = f"{prompt_template}\n\n{raw_text_entry}"

        # Generate summary based on the extracted text
        response = model.generate_content(
            prompt,
            generation_config={"temperature": 0.4, "max_output_tokens": 1024},
        )

        # Store summary
        summary_outputs.append(f"üìÑ **{pdf_file}**:\n{response.text.strip()}")

# ---------------------------------------------
# Step 3: Combine All Summaries and Raw Text
# ---------------------------------------------
full_summary = "\n\n".join(summary_outputs)
full_raw_text = "\n\n".join(raw_texts)

# Save raw text
with open("all_pdf_texts.txt", "w") as raw_text_file:
    raw_text_file.write(full_raw_text)

# Output
print("\n‚úÖ Combined Summary:\n")
print(full_summary)
print("\n‚úÖ Combined Raw Text saved to 'all_pdf_texts.txt'")
print("\n‚úÖ PDFs saved to ./processed_pdfs/")


---------------------------------------------------------------------
import zipfile
import os
import io
import pdfplumber
from google.cloud import storage
from vertexai.generative_models import GenerativeModel
from vertexai import init

# ---------------------------------------------
# Step 0: Init Vertex AI
# ---------------------------------------------
init(project="bhsf-ai-team-projects", location="us-east1")

# ---------------------------------------------
# Step 1: Download ZIP from GCS
# ---------------------------------------------
gcs_bucket = 'gcs-dev-use1-ai-storage-03'
gcs_zip_path = 'intake-summary/Lung.zip'
local_zip_path = '/tmp/Lung.zip'

storage_client = storage.Client()
bucket = storage_client.bucket(gcs_bucket)
blob = bucket.blob(gcs_zip_path)
blob.download_to_filename(local_zip_path)

# ---------------------------------------------
# Step 2: Extract and Collect Raw Text
# ---------------------------------------------
raw_texts = []
model = GenerativeModel("gemini-2.5-flash-lite")

# Load summarization prompt
with open("prompt.txt", "r") as f:
    prompt = f.read().strip()

with zipfile.ZipFile(local_zip_path, 'r') as zip_ref:
    pdf_files = [f for f in zip_ref.namelist() if f.lower().endswith(".pdf")]
    
    for idx, pdf_file in enumerate(pdf_files, 1):
        print(f"üìÑ Reading PDF ({idx}/{len(pdf_files)}): {pdf_file}")
        
        with zip_ref.open(pdf_file) as f:
            pdf_bytes = f.read()

        text = ""
        with pdfplumber.open(io.BytesIO(pdf_bytes)) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"

        raw_entry = f"==== {pdf_file} ====\n{text.strip()}"
        raw_texts.append(raw_entry)

# ---------------------------------------------
# Step 3: Save Raw Text
# ---------------------------------------------
full_raw_text = "\n\n".join(raw_texts)
with open("all_pdf_texts.txt", "w") as f:
    f.write(full_raw_text)

print("\nüìÑ Raw text saved to 'all_pdf_texts.txt'")

# ---------------------------------------------
# Step 4: Generate Combined Summary
# ---------------------------------------------
print("\n‚ú® Generating combined summary...\n")
combined_prompt = f"{prompt}\n\n{full_raw_text}"

response = model.generate_content(
    combined_prompt,
    generation_config={"temperature": 0.4, "max_output_tokens": 2048},
)

combined_summary = response.text.strip()

with open("combined_summary.txt", "w") as f:
    f.write(combined_summary)

print("‚úÖ Combined summary saved to 'combined_summary.txt'\n")

